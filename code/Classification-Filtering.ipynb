{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'generate_global_features_2' from '/var/tmp/ff/tcc/code/generate_global_features_2.py'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import librosa\n",
    "import importlib\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import string as strp\n",
    "import pr_util as util\n",
    "import matplotlib.pyplot as plt\n",
    "import generate_global_features_2 as ggf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm, neighbors\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "importlib.reload(util)\n",
    "importlib.reload(ggf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-2/Gnorimopsar chopi/', '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-4/Sittasomus griseicapillus/', '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-2/Lathrotriccus euleri/']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "num_species      = 3\n",
    "n_min_per_specie = 20\n",
    "n_max_per_specie = 250\n",
    "cv = 10\n",
    "n_global = 4 # number of global functions\n",
    "scoring  = 'f1_weighted'\n",
    "song_or_call = 'song'\n",
    "\n",
    "#data_dirs = util.choose_species(num_species, n_min_per_specie, n_max_per_specie, song_or_call)\n",
    "#data_dirs = util.return_n_most_frequent_species(num_species, song_or_call)\n",
    "data_dirs = ['/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-2/Gnorimopsar chopi/', '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-4/Sittasomus griseicapillus/', '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-2/Lathrotriccus euleri/']\n",
    "print(data_dirs)\n",
    "print(len(data_dirs))\n",
    "\n",
    "#data_dirs = ['/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-4/Synallaxis spixi/', \n",
    "#             '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-4/Trogon surrucura/', \n",
    "#             '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-4/Vanellus chilensis/']\n",
    "\n",
    "#data_dirs = ['/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-1/Basileuterus leucoblepharus/', '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-4/Theristicus caudatus/', '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Parte-2/Gnorimopsar chopi/']\n",
    "#data_dirs_pulse = util.dirs_to_pulse_dirs(data_dirs)\n",
    "\n",
    "\n",
    "#print(data_dirs_pulse)\n",
    "#data_dirs_pulse = ['/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Pulsos_Parte-4/Synallaxis spixi/', \n",
    "#                 '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Pulsos_Parte-4/Trogon surrucura/', \n",
    "#                 '/var/tmp/ff/tcc/dataset/pr_article/S_A_C_Base_Pulsos_Parte-4/Vanellus chilensis/']\n",
    "\n",
    "\n",
    "\n",
    "#data_dirs = ['/Users/felipefelix/USP/tcc/dataset/pr_article/syllables/experimentos_100/Synallaxis spixi/', \n",
    "#             '/Users/felipefelix/USP/tcc/dataset/pr_article/syllables/experimentos_100/Trogon surrucura/', \n",
    "#             '/Users/felipefelix/USP/tcc/dataset/pr_article/syllables/experimentos_100/Vanellus chilensis/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['syllable_dur']\n",
      "number of files loaded: 169\n"
     ]
    }
   ],
   "source": [
    "print(util.FEATURES)\n",
    "feat = util.FEATURES[0]\n",
    "feat = 'syllable_dur_list'\n",
    "#labels_dict_p, labels_p, data_p = ggf.generate_global_features(n_global, feat, data_dirs_pulse, song_or_call, util.GLOBAL_FUNCTIONS, version = None)\n",
    "\n",
    "labels_dict_o, labels_o, data_o = ggf.generate_global_features(n_global, feat, data_dirs, song_or_call, util.GLOBAL_FUNCTIONS, version = 'filtered3')\n",
    "#labels_dict_f1, labels_f1, data_f1 = ggf.generate_global_features(n_global, feat, data_dirs, song_or_call, util.GLOBAL_FUNCTIONS, version = 'filtered1')\n",
    "#labels_dict_f2, labels_f2, data_f2 = ggf.generate_global_features(n_global, feat, data_dirs, song_or_call, util.GLOBAL_FUNCTIONS, version = 'filtered2')\n",
    "#labels_dict_f3, labels_f3, data_f3 = ggf.generate_global_features(n_global, feat, data_dirs, song_or_call, util.GLOBAL_FUNCTIONS, version = 'filtered3')\n",
    "#labels_dict_f4, labels_f4, data_f4 = ggf.generate_global_features(n_global, feat, data_dirs, song_or_call, util.GLOBAL_FUNCTIONS, version = 'filtered4')\n",
    "\n",
    "\n",
    "# MULTI-FEATURES\n",
    "\n",
    "#labels_dict_o, labels_o, data_o = ggf.generate_global_multi_features(n_global, ['spec_band', 'spec_cent'], data_dirs, song_or_call, util.GLOBAL_FUNCTIONS, version = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lathrotriccus Euleri': 2, 'Gnorimopsar Chopi': 0, 'Sittasomus Griseicapillus': 1}\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "169\n",
      "(169, 4)\n",
      "[[ 0.09755102  0.03012353  0.16630385  0.0723356 ]\n",
      " [ 0.04552154  0.0033993   0.04825397  0.0399093 ]\n",
      " [ 0.05238095  0.          0.05238095  0.05238095]\n",
      " [ 0.08269841  0.01636838  0.11034014  0.06780045]\n",
      " [ 0.09397833  0.02200073  0.13124717  0.07179138]\n",
      " [ 0.0821542   0.00605442  0.08820862  0.07609977]\n",
      " [ 0.05166667  0.01445049  0.07297052  0.03587302]\n",
      " [ 0.05018141  0.0253288   0.0755102   0.02485261]\n",
      " [ 0.04439909  0.00680272  0.05120181  0.03759637]\n",
      " [ 0.05843537  0.00269841  0.06113379  0.05573696]]\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(labels_dict_o)\n",
    "#print(labels_dict_p)\n",
    "# print(labels_dict_f1)\n",
    "# print(labels_dict_f2)\n",
    "# print(labels_dict_f3)\n",
    "#print(labels_dict_f4)\n",
    "\n",
    "\n",
    "\n",
    "print(labels_o)\n",
    "#print(labels_p)\n",
    "\n",
    "\n",
    "# print(labels_f1)\n",
    "# print(labels_f2)\n",
    "# print(labels_f3)\n",
    "#print(labels_f4)\n",
    "\n",
    "print(len(labels_o))\n",
    "#print(len(labels_p))\n",
    "\n",
    "# print(len(labels_f1))\n",
    "# print(len(labels_f2))\n",
    "# print(len(labels_f3))\n",
    "#print(len(labels_f4))\n",
    "\n",
    "print(data_o.shape)\n",
    "print(data_o[:10])\n",
    "#print(data_p[:10])\n",
    "#print(data_f4[:10])\n",
    "\n",
    "# print(data_f1[:10])\n",
    "# print(data_f2[:10])\n",
    "# print(data_f3[:10])\n",
    "\n",
    "print(len(data_o))\n",
    "#print(len(data_p))\n",
    "#print(len(data_f4))\n",
    "# print(len(data_f1))\n",
    "# print(len(data_f2))\n",
    "# print(len(data_f3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.plot_scatter(data_o[:,0], data_o[:,1], labels_o, feat + ' mean', feat + ' std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.plot_scatter(data_f4[:,0], data_f4[:,1], labels_f4, feat + ' mean', feat + ' std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.plot_scatter(data_f1[:,2], data_f1[:,3], labels_f1, feat + ' mean', feat + ' std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.plot_scatter(data_f2[:,2], data_f2[:,3], labels_f2, feat + ' mean', feat + ' std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_scores(clf, clf_name, data, labels, scoring, cv = cv):\n",
    "    scores  = cross_val_score(clf, data, labels, n_jobs = -1, cv = cv, scoring = scoring, verbose = 3)\n",
    "    print(scores)\n",
    "    print('{0} - {1}: {2:.2f} (+/- {3:.2f})'.format(clf_name, scoring, scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.2948717948717949, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ...................... , score=0.25925925925925924, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ...................... , score=0.40774410774410774, total=   0.0s\n",
      "[CV] ....................... , score=0.3218954248366013, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................... , score=0.22491349480968859, total=   0.0s\n",
      "[CV] ...................... , score=0.35773601398601396, total=   0.0s\n",
      "[CV] ....................... , score=0.3743131868131868, total=   0.0s\n",
      "[CV] ....................... , score=0.3199300699300699, total=   0.0s\n",
      "[CV] ........................ , score=0.451486013986014, total=   0.0s\n",
      "[CV] ....................... , score=0.3787878787878788, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25925926  0.29487179  0.40774411  0.32189542  0.22491349  0.35773601\n",
      "  0.37431319  0.31993007  0.45148601  0.37878788]\n",
      "kNN - f1_weighted: 0.34 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "clf     = neighbors.KNeighborsClassifier(3, weights = 'uniform')\n",
    "\n",
    "generate_scores(clf, 'kNN', data_o, labels_o, scoring)\n",
    "\n",
    "#generate_scores(clf, 'kNN', data_p, labels_p, scoring)\n",
    "#generate_scores(clf, 'kNN', data_f1, labels_f1, scoring)\n",
    "#generate_scores(clf, 'kNN', data_f2, labels_f2, scoring)\n",
    "#generate_scores(clf, 'kNN', data_f3, labels_f3, scoring)\n",
    "#generate_scores(clf, 'kNN', data_f4, labels_f4, scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.33660130718954245, total=   0.0s\n",
      "[CV] ....................... , score=0.4122899159663866, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.12626262626262624, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.101010101010101, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.2215007215007215, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.2215007215007215, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.07894736842105264, total=   0.0s\n",
      "[CV] ....................... , score=0.2048611111111111, total=   0.0s\n",
      "[CV] .................................... , score=0.275, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.2986111111111111, total=   0.0s\n",
      "[ 0.12626263  0.1010101   0.22150072  0.22150072  0.33660131  0.41228992\n",
      "  0.275       0.20486111  0.07894737  0.29861111]\n",
      "gNB - f1_weighted: 0.23 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "clf     = GaussianNB()\n",
    "\n",
    "generate_scores(clf, 'gNB', data_o, labels_o, scoring)\n",
    "#generate_scores(clf, 'gNB', data_p, labels_p, scoring)\n",
    "#generate_scores(clf, 'gNB', data_f1, labels_f1, scoring)\n",
    "#generate_scores(clf, 'gNB', data_f2, labels_f2, scoring)\n",
    "#generate_scores(clf, 'gNB', data_f3, labels_f3, scoring)\n",
    "#generate_scores(clf, 'gNB', data_f4, labels_f4, scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.2177777777777778, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.2177777777777778, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.32208994708994715, total=   0.0s\n",
      "[CV] ...................... , score=0.32208994708994715, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.24019607843137258, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.20454545454545453, total=   0.0s\n",
      "[CV] ...................... , score=0.20454545454545453, total=   0.0s\n",
      "[CV] ...................... , score=0.20454545454545453, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/gradmac/fsfelix/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... , score=0.20454545454545453, total=   0.0s\n",
      "[CV] ...................... , score=0.20454545454545453, total=   0.0s\n",
      "[ 0.21777778  0.21777778  0.32208995  0.32208995  0.24019608  0.20454545\n",
      "  0.20454545  0.20454545  0.20454545  0.20454545]\n",
      "SVM - f1_weighted: 0.23 (+/- 0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel = 'linear', max_iter=-1, C = 1, decision_function_shape='ovr')\n",
    "\n",
    "generate_scores(clf, 'SVM', data_o, labels_o, scoring)\n",
    "#generate_scores(clf, 'SVM', data_p, labels_p, scoring)\n",
    "#generate_scores(clf, 'SVM', data_f1, labels_f1, scoring)\n",
    "#generate_scores(clf, 'SVM', data_f2, labels_f2, scoring)\n",
    "#generate_scores(clf, 'SVM', data_f3, labels_f3, scoring)\n",
    "#generate_scores(clf, 'SVM', data_f4, labels_f4, scoring)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
